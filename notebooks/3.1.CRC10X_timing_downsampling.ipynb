{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500bd294-703e-4d74-9955-3bb5fbba8cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n",
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import nbinom, poisson, binom\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from Bio import Phylo\n",
    "from tqdm.notebook import tqdm\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fe0ef1-8b03-4edc-a8de-d48198048832",
   "metadata": {},
   "source": [
    "## merge all Ns into One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a70d554-62cd-4f1d-a77a-cb77f55315cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHYDIR=\"/data2/kantian/LineageTracing/SMALT/0.Results/2.filteredNT_re/\"\n",
    "###############################################################\n",
    "##------------------------merge all IBD_CRC N (3K)------------------------\n",
    "###############################################################\n",
    "samples=[\"2_N\",\"4_N\",\"5_N\",\"16_N\",\"19_N\",\"47_N1\",\"47_N4\",\"47_N5\",\"47_N6\",\"47_N8\",\n",
    "                    \"49_N\",\"50_N\",\"65_N\",\"66_N\",\"17_N\",\"151_N\"] ## 18_N, 132_N\n",
    "PHYDIR=\"/data2/kantian/LineageTracing/SMALT/0.Results/2.final_phy_re/\"\n",
    "data=pd.DataFrame()\n",
    "for mySample in samples:\n",
    "    phy = pd.read_csv(PHYDIR+mySample+\"_filtered_re.phy\",sep = \" \",header = None,skiprows=[0,1], names = [\"nam\",\"bi\"],index_col = 0)\n",
    "    phy.index = [mySample+\"_\"+i.split(\"_\")[1] for i in phy.index]\n",
    "    data = pd.concat([data, phy])\n",
    "numR = data.shape[0]\n",
    "header = pd.DataFrame({\"bi\":{\"ref\":''.join(map(str,[0]*3004)),str(numR+1):\"3004\"}})\n",
    "data.to_csv(PHYDIR+\"IBD_N_merged_3k.phy\",sep = \" \",index=True, header = None)\n",
    "###############################################################\n",
    "##------------------------merge all IBD_CRC N (1.5K)-----------------------\n",
    "###############################################################\n",
    "samples=[\"142_N\",\"148_N\"] ## 18_N, 132_N\n",
    "PHYDIR=\"/data2/kantian/LineageTracing/SMALT/0.Results/2.final_phy_re/\"\n",
    "data=pd.DataFrame()\n",
    "for mySample in samples:\n",
    "    phy = pd.read_csv(PHYDIR+mySample+\"_filtered_re.phy\",sep = \" \",header = None,skiprows=[0,1], names = [\"nam\",\"bi\"],index_col = 0)\n",
    "    phy.index = [mySample+\"_\"+i.split(\"_\")[1] for i in phy.index]\n",
    "    data = pd.concat([data, phy])\n",
    "numR = data.shape[0]\n",
    "header = pd.DataFrame({\"bi\":{\"ref\":''.join(map(str,[0]*1421)),str(numR+1):\"1421\"}})\n",
    "data.to_csv(PHYDIR+\"IBD_N_merged_1.5k.phy\",sep = \" \",index=True, header = None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7d24a0-7dfd-47ec-bb49-741861081bf0",
   "metadata": {},
   "source": [
    "## 1. downsampling: if more than 1000 cells, downsampling 1000 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74175b60-7d0e-41b9-bdf4-cb12d4ffe4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67057638-0c4f-406d-acb2-922ccdd76a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHYDIR=\"/data2/kantian/LineageTracing/SMALT/0.Results/2.final_phy_re/\"\n",
    "OUTDIR=\"/data2/kantian/LineageTracing/SMALT/0.Results/3.IBD_mergeN1000_T1000/\"\n",
    "if not os.path.exists(OUTDIR):\n",
    "    os.mkdir(OUTDIR)\n",
    "###############################################################\n",
    "##------------------------CRC 10X (3K)------------------------\n",
    "###############################################################\n",
    "samples=[\"132_T1\",\"151_T4\",\"17_T4\",\"18_T3\",\"18_T4\"]\n",
    "\n",
    "samplingSize=1000\n",
    "for mySample in samples:\n",
    "    iter=1\n",
    "    while iter<=20:\n",
    "        N = pd.read_csv(PHYDIR+\"IBD_N_merged_3k.phy\",sep = \" \",header = None,skiprows=[0,1], names = [\"nam\",\"bi\"],index_col = 0)\n",
    "        T = pd.read_csv(PHYDIR+mySample+\"_filtered_re.phy\",sep = \" \",header = None,skiprows=[0,1], names = [\"nam\",\"bi\"],index_col = 0)\n",
    "        if len(N)>samplingSize:\n",
    "            N=N.sample(n=samplingSize)\n",
    "        if len(T)>samplingSize:\n",
    "            T=T.sample(n=samplingSize)\n",
    "        M=pd.concat([N,T])\n",
    "        numR = M.shape[0]\n",
    "        # print(numR)\n",
    "        header = pd.DataFrame({\"bi\":{\"ref\":''.join(map(str,[0]*3004)),str(numR+1):\"3004\"}})\n",
    "        data = pd.concat([header, M])\n",
    "        data.to_csv(OUTDIR+mySample+\"_sampling\"+str(samplingSize)+\"_\"+str(iter)+\".phy\",sep = \" \",index=True, header = None)\n",
    "        iter+=1\n",
    "###############################################################\n",
    "##------------------------merge all IBD_CRC N (1.5K)-----------------------\n",
    "###############################################################\n",
    "samples=[\"142_T1\",\"142_T2\",\"142_T5-4\",\"148_T1\",\"148_T3\"]\n",
    "\n",
    "samplingSize=1000\n",
    "for mySample in samples:\n",
    "    iter=1\n",
    "    while iter<=20:\n",
    "        N = pd.read_csv(PHYDIR+\"IBD_N_merged_1.5k.phy\",sep = \" \",header = None,skiprows=[0,1], names = [\"nam\",\"bi\"],index_col = 0)\n",
    "        T = pd.read_csv(PHYDIR+mySample+\"_filtered_re.phy\",sep = \" \",header = None,skiprows=[0,1], names = [\"nam\",\"bi\"],index_col = 0)\n",
    "        if len(N)>samplingSize:\n",
    "            N=N.sample(n=samplingSize)\n",
    "        if len(T)>samplingSize:\n",
    "            T=T.sample(n=samplingSize)\n",
    "        M=pd.concat([N,T])\n",
    "        numR = M.shape[0]\n",
    "        # print(numR)\n",
    "        header = pd.DataFrame({\"bi\":{\"ref\":''.join(map(str,[0]*1421)),str(numR+1):\"1421\"}})\n",
    "        data = pd.concat([header, M])\n",
    "        data.to_csv(OUTDIR+mySample+\"_sampling\"+str(samplingSize)+\"_\"+str(iter)+\".phy\",sep = \" \",index=True, header = None)\n",
    "        iter+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf2493-98f9-4142-b1de-e185ebd00571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0e6cabc-5f87-4099-b9fc-d1b3bd83164f",
   "metadata": {},
   "source": [
    "## 2. downsampling: min(len(N),len(T),1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcbf4ee2-76f8-4888-8106-9cd750b1cb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132_T1\n",
      "2629\n",
      "151_T4\n",
      "426\n",
      "17_T4\n",
      "290\n",
      "18_T3\n",
      "1007\n",
      "18_T4\n",
      "161\n",
      "142_T1\n",
      "5691\n",
      "142_T2\n",
      "5853\n",
      "142_T5-4\n",
      "749\n",
      "148_T1\n",
      "1626\n",
      "148_T3\n",
      "2324\n"
     ]
    }
   ],
   "source": [
    "samples=[\"132_T1\",\"151_T4\",\"17_T4\",\"18_T3\",\"18_T4\",\"142_T1\",\"142_T2\",\"142_T5-4\",\"148_T1\",\"148_T3\"]\n",
    "for mySample in samples:\n",
    "    T = pd.read_csv(PHYDIR+mySample+\"_filtered_re.phy\",sep = \" \",header = None,skiprows=[0,1], names = [\"nam\",\"bi\"],index_col = 0)\n",
    "    print(mySample)\n",
    "    print(len(T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "971d1111-e92c-4ad4-9dc5-6249edf79742",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHYDIR=\"/data2/kantian/LineageTracing/SMALT/0.Results/2.final_phy_re/\"\n",
    "OUTDIR=\"/data2/kantian/LineageTracing/SMALT/0.Results/3.IBD_merge_NTsame/\"\n",
    "if not os.path.exists(OUTDIR):\n",
    "    os.mkdir(OUTDIR)\n",
    "###############################################################\n",
    "##------------------------CRC 10X (3K)------------------------\n",
    "###############################################################\n",
    "samples=[\"151_T4\",\"17_T4\",\"18_T4\"]\n",
    "for mySample in samples:\n",
    "    iter=1\n",
    "    while iter<=20:\n",
    "        N = pd.read_csv(PHYDIR+\"IBD_N_merged_3k.phy\",sep = \" \",header = None,skiprows=[0,1], names = [\"nam\",\"bi\"],index_col = 0)\n",
    "        T = pd.read_csv(PHYDIR+mySample+\"_filtered_re.phy\",sep = \" \",header = None,skiprows=[0,1], names = [\"nam\",\"bi\"],index_col = 0)\n",
    "        samplingSize=min(len(N),len(T),1000)\n",
    "        if len(N)>samplingSize:\n",
    "            N=N.sample(n=samplingSize)\n",
    "        if len(T)>samplingSize:\n",
    "            T=T.sample(n=samplingSize)\n",
    "        M=pd.concat([N,T])\n",
    "        numR = M.shape[0]\n",
    "        # print(numR)\n",
    "        header = pd.DataFrame({\"bi\":{\"ref\":''.join(map(str,[0]*3004)),str(numR+1):\"3004\"}})\n",
    "        data = pd.concat([header, M])\n",
    "        data.to_csv(OUTDIR+mySample+\"_sampling\"+str(samplingSize)+\"_\"+str(iter)+\".phy\",sep = \" \",index=True, header = None)\n",
    "        iter+=1\n",
    "###############################################################\n",
    "##------------------------merge all IBD_CRC N (1.5K)-----------------------\n",
    "###############################################################\n",
    "samples=[\"142_T5-4\"]\n",
    "for mySample in samples:\n",
    "    iter=1\n",
    "    while iter<=20:\n",
    "        N = pd.read_csv(PHYDIR+\"IBD_N_merged_1.5k.phy\",sep = \" \",header = None,skiprows=[0,1], names = [\"nam\",\"bi\"],index_col = 0)\n",
    "        T = pd.read_csv(PHYDIR+mySample+\"_filtered_re.phy\",sep = \" \",header = None,skiprows=[0,1], names = [\"nam\",\"bi\"],index_col = 0)\n",
    "        samplingSize=min(len(N),len(T),1000)\n",
    "        if len(N)>samplingSize:\n",
    "            N=N.sample(n=samplingSize)\n",
    "        if len(T)>samplingSize:\n",
    "            T=T.sample(n=samplingSize)\n",
    "        M=pd.concat([N,T])\n",
    "        numR = M.shape[0]\n",
    "        # print(numR)\n",
    "        header = pd.DataFrame({\"bi\":{\"ref\":''.join(map(str,[0]*1421)),str(numR+1):\"1421\"}})\n",
    "        data = pd.concat([header, M])\n",
    "        data.to_csv(OUTDIR+mySample+\"_sampling\"+str(samplingSize)+\"_\"+str(iter)+\".phy\",sep = \" \",index=True, header = None)\n",
    "        iter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bac2b9c-0856-4e23-aba8-a45fff8993f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7410"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ef743-f166-4713-91af-8c3bb8986e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smalt_python3.11",
   "language": "python",
   "name": "smalt_python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

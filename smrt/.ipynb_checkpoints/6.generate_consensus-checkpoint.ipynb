{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd51bd15-2c47-43b0-8238-a0e78618f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from Bio import SeqIO, AlignIO\n",
    "import pysam\n",
    "# from Bio.Align.Applications import PrankCommandline\n",
    "# import subprocess\n",
    "from collections import Counter\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0bf7e3f-d8fc-4e16-b748-e69b789b2c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupUMI(ucfile):\n",
    "    uc = pd.read_csv(ucfile,delimiter=\"\\t\",header=None,usecols=[0,1,8])\n",
    "    uc.columns=[\"a\",\"cluster\",\"name\"]\n",
    "    uc = uc.loc[uc[\"a\"].isin([\"C\",\"H\"])]\n",
    "    # uc.index=uc[\"name\"]\n",
    "    uc = uc.loc[uc.duplicated(subset='cluster', keep=False)]\n",
    "    return(uc)\n",
    "\n",
    "\n",
    "def dictBam(bamfile, outDict):\n",
    "    \"\"\"\n",
    "    i\n",
    "    \"\"\"\n",
    "    with pysam.AlignmentFile(bamfile, \"rb\", check_sq=False) as infile:\n",
    "        with open(outDict, \"w\") as outfile:\n",
    "#         dic ={}\n",
    "            for read in infile.fetch(until_eof=True):\n",
    "                dic = {}\n",
    "                if not read.has_tag(\"MD\") or (query_seq := read.query_sequence) is None or read.is_secondary:\n",
    "                    return None\n",
    "\n",
    "                readDict = callMutation(read)\n",
    "                dic[read.qname] = readDict\n",
    "                outfile.write(f\"{read.qname}\\t{readDict[0]}\\t{readDict[1]}\\t{readDict[2]}\\t{readDict[3]}\\n\")\n",
    "\n",
    "def callMutation(read):\n",
    "    \"\"\"\n",
    "    get mutations and indels from a read which has MD tag in sam/bam\n",
    "    \"\"\"\n",
    "\n",
    "    mut_type = []\n",
    "    mut_qual= []\n",
    "    indel_type = []\n",
    "    indel_qual =[]\n",
    "\n",
    "    ref_index = read.reference_start-1\n",
    "    query_index = -1\n",
    "    I_index = [0]\n",
    "    I_qual = []\n",
    "    D_index = []\n",
    "    D_qual = []\n",
    "\n",
    "    \n",
    "    \n",
    "    for query_pos, ref_pos, ref_base in read.get_aligned_pairs(with_seq=True): #matches_only=True, # if True, no None on either side\n",
    "\n",
    "        if query_pos is None: # Deletion\n",
    "            ref_index += 1\n",
    "            D_index.append(ref_index)\n",
    "            D_qual.append(read.query_qualities[query_index])\n",
    "#                     if D_index[-1]-D_index[-2] >1:\n",
    "#                         indel_type.append(str(ref_index)+\"D\")\n",
    "#                         indel_qual.append(read.query_qualities[query_index])\n",
    "\n",
    "        elif ref_pos is None: # Insertion\n",
    "            query_index +=1\n",
    "            I_index.append(ref_index)\n",
    "            I_qual.append(read.query_qualities[query_index])\n",
    "            if I_index[-1]-I_index[-2] >1:\n",
    "                indel_type.append(str(ref_index)+\"I\")\n",
    "                indel_qual.append(read.query_qualities[query_pos])\n",
    "\n",
    "        elif ref_base.islower():\n",
    "            ref_index += 1\n",
    "            query_index +=1\n",
    "            mut_type.append(str(ref_pos)+ref_base.upper()+read.query_sequence[query_pos])\n",
    "            mut_qual.append(read.query_qualities[query_pos])\n",
    "\n",
    "        else:\n",
    "            ref_index += 1\n",
    "            query_index +=1\n",
    "    D = concatDel(D_index, D_qual,\"D\")\n",
    "    indel_type = indel_type + D[0]\n",
    "    indel_qual = indel_qual + D[1]\n",
    "    return(mut_type, mut_qual, indel_type, indel_qual)\n",
    "\n",
    "\n",
    "def concatDel(A,B,type=\"D\"):\n",
    "    A.append(-1)\n",
    "    l = len(A)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    inds = []\n",
    "    OUT= []\n",
    "    QUAL = []\n",
    "    while i < l-2:\n",
    "        while j < l-1:\n",
    "            if not (A[j+1] - A[j] - 1):\n",
    "                j += 1\n",
    "            else:\n",
    "                i = j + 1\n",
    "                j = i\n",
    "                inds.append(j)\n",
    "    inds.insert(0, 0)\n",
    "    for i in range(len(inds)-1):\n",
    "        if not inds[i+1] - inds[i] - 1:\n",
    "            OUT.append(str(A[inds[i]])+type)\n",
    "            QUAL.append(B[inds[i]])\n",
    "        else:\n",
    "            OUT.append('{}-{}{}'.format(A[inds[i]], A[inds[i+1]-1],type))\n",
    "            qual = B[inds[i]:inds[i+1]]\n",
    "            qual_avg = int(sum(qual)/len(qual))\n",
    "            QUAL.append(qual_avg)\n",
    "    return(OUT, QUAL)\n",
    "\n",
    "# def generateConsensus(dictbam, uc, my_cluster, frequency_threshold = 0.5, quality_threshold = 4):\n",
    "#     uc = groupUMI(ucfile)\n",
    "#     my_cluster = 2\n",
    "#     clusters = ucsam.cluster.unique()\n",
    "#     for my_cluster in clusters:\n",
    "#         sub=uc.loc[uc[\"cluster\"]==my_cluster]\n",
    "#         if len(sub)>=2:\n",
    "#             ssMuts = ccSeq(dictbam, sub, frequency_threshold, quality_threshold)\n",
    "            \n",
    "            \n",
    "\n",
    "def ccSeq(sub, frequency_threshold, quality_threshold):\n",
    "    \"\"\"\n",
    "    find cluster consensus mutations in each uc group\n",
    "    \"\"\"\n",
    "    num = len(sub)\n",
    "    ccMuts = []\n",
    "    \n",
    "    muts =sub[\"mut_type\"].to_numpy()\n",
    "    muts = removeBracket(muts, qual = False)\n",
    "    mut_quals =sub[\"mut_qual\"].to_numpy()\n",
    "    mut_quals = removeBracket(mut_quals, qual = True)\n",
    "    indels =sub[\"indel_type\"].to_numpy()\n",
    "    indels = removeBracket(indels, qual = False)\n",
    "    indel_quals =sub[\"indel_qual\"].to_numpy()\n",
    "    indel_quals = removeBracket(indel_quals, qual = True)\n",
    "      \n",
    "    fM = filterMuts(muts, mut_quals, num, frequency_threshold, quality_threshold)\n",
    "    fID = filterMuts(indels, indel_quals, num, frequency_threshold, quality_threshold)\n",
    "    ccMuts.append(fM)\n",
    "    ccMuts.append(fID)\n",
    "    ccMuts = flatList(ccMuts)\n",
    "    return(ccMuts)\n",
    "\n",
    "def removeBracket(s,qual=True):\n",
    "    \"\"\"\n",
    "    ori: [\"['2048TC']\" '[]' \"['1283CT', '1529GC']\"]\n",
    "    transformed: ['2048TC','1283CT','1529GC']\n",
    "    \"\"\"\n",
    "    su = []\n",
    "    if s is not None:\n",
    "        for s_sub in s:\n",
    "            s_sub = s_sub.replace(\"[\",\"\")\n",
    "            s_sub = s_sub.replace(\"]\",\"\")\n",
    "            s_sub = s_sub.replace(\"'\",\"\")\n",
    "            s_sub = s_sub.split(\",\")\n",
    "            for s_sub_sub in s_sub:\n",
    "                if s_sub_sub != '':\n",
    "                    s_sub_sub = s_sub_sub.replace(\" \",\"\")\n",
    "                    if qual:\n",
    "                        su.append(int(s_sub_sub))\n",
    "                    else:\n",
    "                        su.append(str(s_sub_sub))\n",
    "    return(su)\n",
    "    \n",
    "def filterMuts(muts, mut_quals, num, frequency_threshold = 0.5, quality_threshold = 50):\n",
    "    \"\"\"\n",
    "    filter mutations/indels with frequency >= frequency_threshold\n",
    "    \"\"\"\n",
    "    cs = [ele for ele, cnt in Counter(muts).items() if cnt >= num*frequency_threshold]\n",
    "    csMuts = []\n",
    "    if len(cs) >0:\n",
    "        for mutType in cs:\n",
    "            quals = []\n",
    "            for b,q in zip(muts, mut_quals):\n",
    "                if b == mutType:\n",
    "                    quals.append(q)\n",
    "            if statistics.mean(quals) >= quality_threshold:\n",
    "                csMuts.append(mutType)\n",
    "    return(csMuts)\n",
    "\n",
    "\n",
    "def flatList(Alist):\n",
    "    flat_list = []\n",
    "    for sublist in Alist:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)        \n",
    "    return(flat_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d7065-cdd8-4933-9f60-3fafaa72da24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_1T\n",
      "2_3T\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    generate consensus\n",
    "    \"\"\"\n",
    "        \n",
    "    SAMPLE_BARCODES = \"/data/zhaolian/LineageTracing/DSS/PacBio/CCS5passes/samples_all.txt\"\n",
    "    BAMDIR=\"/data/zhaolian/LineageTracing/DSS/PacBio/CCS5passes/5.bam_split/\"\n",
    "    UCDIR=\"/data/zhaolian/LineageTracing/DSS/PacBio/CCS5passes/4.umi_clustering/\"\n",
    "    OUTDIR=\"/data/zhaolian/LineageTracing/DSS/PacBio/CCS5passes/6.umiConsensus/\"\n",
    "    numUC=3 ## number of ccs reads in one consensus cluster\n",
    "    mutFreq=0.6 ## export the mutation if mutation frequency >= mutFreq \n",
    "    quality_threshold = 50 ## mapping quality\n",
    "\n",
    "    if not os.path.exists(OUTDIR):\n",
    "        os.mkdir(OUTDIR)\n",
    "\n",
    "    with open(SAMPLE_BARCODES,\"r\") as f_barcode:\n",
    "        for line in f_barcode.readlines():\n",
    "            sample = line.replace(\"\\n\", \"\").split(\"\\t\")[0]\n",
    "            print(sample)\n",
    "\n",
    "            bamfile = BAMDIR+sample+\".bam\"\n",
    "            outDict = OUTDIR+sample+\"_mutations_\"+str(numUC)+\"_\"+str(mutFreq)+\"_\"+str(quality_threshold)+\".txt\" ## output file 1\n",
    "            dictBam(bamfile, outDict)\n",
    "\n",
    "            ucfile = UCDIR+sample+\"_umi_UsearchClusters.uc\"\n",
    "            outfile = OUTDIR+sample+\"_umiConsensus_\"+str(numUC)+\"_\"+str(mutFreq)+\"_\"+str(quality_threshold)+\".tsv\" ## output file 2\n",
    "\n",
    "            uc = groupUMI(ucfile)\n",
    "            colnames =[\"name\",\"mut_type\", \"mut_qual\", \"indel_type\", \"indel_qual\"]\n",
    "            dictbam = pd.read_csv(outDict,delimiter=\"\\t\",header=None,names=colnames)\n",
    "            ucbam=pd.merge(uc,dictbam, on=\"name\",how=\"inner\")\n",
    "\n",
    "\n",
    "            clusters = uc.cluster.unique()\n",
    "            with open(outfile,\"w\") as f:\n",
    "                for(my_cluster) in clusters:\n",
    "                    sub=ucbam.loc[ucbam[\"cluster\"]==my_cluster]\n",
    "                    if len(sub) >= numUC:\n",
    "                        ssMuts = ccSeq(sub, mutFreq, quality_threshold)\n",
    "                        if len(ssMuts) >0:\n",
    "                            s=len(ssMuts)\n",
    "    #                         print(ssMuts)\n",
    "                            f.write(f\"{my_cluster}\\t{s}\\t{','.join([i for i in ssMuts])}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b18980-33f8-4389-a425-dfe989e5f254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
